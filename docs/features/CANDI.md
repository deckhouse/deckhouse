---
title: Подсистема Kubernetes Cluster and Infrastructure
permalink: /features/candi.html
---

<!--Отсутствует информация по -->
<!-- - 030-cloud-provider-aws-->
<!-- - 030-cloud-provider-gcp-->
<!-- - 030-cloud-provider-openstack-->
<!-- - 030-cloud-provider-vsphere-->
<!-- - 030-cloud-provider-yandex-->
<!-- - 040-terraform-manager-->
<!-- - 041-kube-proxy-->

<!--Есть информация по -->
<!-- - + 040-control-plane-manager-->
<!-- - + 040-node-manager-->

<!--Не надо писать про-->
<!-- - 160-control-plane-configurator-->
<!-- - 700-sysctl-tuner-->
<!-- - 800-systemd-slices-cleaner-->

Отвечает за то, чтобы кластер **одинаково** работал на **любой поддерживаемой инфраструктуре**:
- в облаках (смотри информацию по соответствующему Cloud provider)
- на виртуальных машинах или железе (включая on-premises)
- в гибридной инфраструктуре.

Для этого, подсистема CandI автоматически настраивает и управляет как [узлами кластера](/modules/040-node-manager/), так и его [control-plane](/modules/040-control-plane-manager/), постоянно поддерживая их актуальную конфигурацию (используя инструменты Terraform).

Подсистема candi позволяет легко выполнять такие нетривиальные операции с control-plane и узлами кластера, как:
- миграция между single-master и multi-master схемами
- маштабирование master-узлов
- обновление версий компонентов.

Операции выполняются по умным и безопасным алгоритмам, с возможностью пользователю контролировать/управлять происходящими процессами.

Также, candi берет на себя заботу о состоянии сертификатов используемых при работе с control-plane, — автоматически выполняя выпуск, продление сертификатов и настройку конфигурации kubectl.

Подсистема candi заменяет ресурсы относящиеся к `kube-proxy` от `kubeadm` (соответствующие DaemonSet, ConfigMap, RBAC) собственными версиями.

Интеграция между подсистемами Deckhouse, позволяет сразу получить эффективный мониторинг и обеспечить приемлемый уровень безопасности. Например, интеграция подсистем candi и auth позволяет легко организовать надежный доступ к API-серверу кластера через публичный IP-адрес, в том числе с возможностью работы через внешний провайдер аутентификации.

Docker-образы всех компонент Deckhouse, включая `control-plane`, хранятся в высокодоступном и геораспределенном Docker-registry, доступном с фиксированного набора IP-адресов (для удобства организации доступа из изолированных контуров).

