---
title: Как устроена доставка логов
permalink: ru/admin/configuration/logging/log-shipper/overview.html
lang: ru
---

Сбор и доставка логов из узлов и подов кластера Deckhouse во внутреннюю или внешние системы хранения
производятся при помощи встроенного модуля `log-shipper`.

## Возможности модуля

- Поддержка различных получателей, включая Elasticsearch, Splunk, Logstash,
  внутреннее хранилище на базе Grafana Loki и другие.
- Фильтрация и обогащение логов перед отправкой.
- Поддержка нескольких форматов логов: JSON, syslog, CEF.
- Опциональная буферизация логов для повышения производительности.

## Механизм работы модуля

Модуль `log-shipper` использует [Vector](https://vector.dev/) в качестве агента логирования.
На каждом узле кластера запускается отдельный экземпляр `log-shipper`, который настраивается на основе ресурсов Deckhouse.
Комбинация этих настроек для сбора и доставки логов образует *pipeline*.

![Архитектура log-shipper](../../images/log-shipper/log_shipper_architecture.svg)

<!-- Исходник схемы: https://docs.google.com/drawings/d/1cOm5emdfPqWp9NT1UrB__TTL31lw7oCgh0VicQH-ouc/edit -->

1. Deckhouse отслеживает ресурсы ClusterLoggingConfig, ClusterLogDestination и PodLoggingConfig (#TODO ссылка на CR).
1. На основе заданных параметров Deckhouse автоматически создаёт конфигурационный файл и сохраняет его в Secret в Kubernetes.
1. Secret монтируется на все поды агентов `log-shipper`.
   При изменении конфигурации обновление происходит автоматически с помощью сайдкар-контейнера `reloader`.

## Схемы доставки логов

В `log-shipper` поддерживаются различные топологии доставки логов
в зависимости от требований к надёжности и потреблению ресурсов.  

### Распределенная

Агенты `log-shipper` отправляют логи напрямую в хранилище, например, Loki или Elasticsearch.

![log-shipper distributed](../../images/log-shipper/log_shipper_distributed.svg)

<!-- Исходник картинок: https://docs.google.com/drawings/d/1FFuPgpDHUGRdkMgpVWXxUXvfZTsasUhEh8XNz7JuCTQ/edit -->

Преимущества:

- Простая настройка.
- Доступна «из коробки» без дополнительных зависимостей, кроме хранилища.

Недостатки:

- Сложные трансформации потребляют больше ресурсов на узлах для приложений.

### Централизованная

Все логи отправляются в один из доступных агрегаторов, например, Logstash или Vector.
Агенты на узлах отправляют логи как можно быстрее, потребляя минимальное количество ресурсов.
Сложные трансформации выполняются на стороне агрегатора.

![log-shipper centralized](../../images/log-shipper/log_shipper_centralized.svg)

<!-- Исходник картинок: https://docs.google.com/drawings/d/1TL-YUBk0CKSJuKtRVV44M9bnYMq6G8FpNRjxGxfeAhQ/edit -->

Преимущества:

- Снижает потребление ресурсов на узлах для приложений.
- Пользователи могут настроить в агрегаторе любые трансформации и слать логи в гораздо большее количество хранилищ.

Недостатки:

- Требует выделенных узлов под агрегаторы. Их количество может увеличиваться в зависимости от нагрузки.

### Потоковая

Главная задача данной архитектуры — как можно быстрее отправить логи в очередь сообщений (например, Kafka),
из которой они в служебном порядке передаются в долгосрочное хранилище для дальнейшего анализа.

![log-shipper stream](../../images/log-shipper/log_shipper_stream.svg)

<!-- Исходник картинок: https://docs.google.com/drawings/d/1R7vbJPl93DZPdrkSWNGfUOh0sWEAKnCfGkXOvRvK3mQ/edit -->

Преимущества:

- Снижает потребление ресурсов на узлах для приложений.
- Пользователи могут настроить в агрегаторе любые трансформации и слать логи в гораздо большее количество хранилищ.
- Высокая надёжность. Подходит для инфраструктуры, в которой доставка логов является приоритетной задачей.

Недостатки:

- Добавляет промежуточное звено (очередь сообщений).
- Требует выделенных узлов под агрегаторы. Их количество может увеличиваться в зависимости от нагрузки.

## Обработка логов

### Фильтры сообщений

Перед отправкой логов `log-shipper` может отфильтровывать ненужные записи,
чтобы снизить количество сообщений, отправляемых в хранилище.
Для этого модуль задействует `label filter` и `log filter`.

![log-shipper pipeline](../../images/log-shipper/log_shipper_pipeline.svg)

<!-- Исходник картинок: https://docs.google.com/drawings/d/1SnC29zf4Tse4vlW_wfzhggAeTDY2o9wx9nWAZa_A6RM/edit -->

Фильтры запускаются сразу после объединения строк с помощью multiline-парсинга.

- `label filter`:
  - Правила применяются к метаданным сообщений.
  - Поля для метаданных (или лейблов) наполняются на основании источника логов,
    поэтому для разных источников будет разный набор полей.
  - Правила используются, например, чтобы исключить сообщения из определенного контейнера или пода,
    соответствующих заданной метке.
- `log filter`:
  - Правила применяются к исходному сообщению.
  - Позволяет исключить сообщение на основании значения JSON-поля.
  - Если сообщение не в формате JSON, можно использовать регулярное выражение для поиска по строке.

Оба фильтра имеют единую структуру конфигурации:

- `field` — источник данных для запуска фильтрации. Чаще всего это значение лейбла или поля из JSON-документа.
- `operator` — действие для сравнения. Доступные варианты: `In`, `NotIn`, `Regex`, `NotRegex`, `Exists`, `DoesNotExist`.
- `values` — эта опция имеет разные значения для разных операторов:
  - `In`, `NotIn` — значение поля должно равняться или не равняться одному из значений в списке `values`.
  - `Regex`, `NotRegex` — значение должно соответствовать хотя бы одному
    или не соответствовать ни одному регулярному выражению из списка `values`.
  - `Exists`, `DoesNotExist` — не поддерживается.

{% alert level="info" %}
Дополнительные лейблы (`extraLabels`) добавляются на этапе **Destination**, поэтому фильтрация логов по ним невозможна.
{% endalert %}

### Метаданные

При обработке логов `log-shipper` автоматически обогащает сообщения метаданными в зависимости от их источника.
Обогащение происходит на этапе `Source`.

#### Kubernetes

При сборе логов из подов и узлов Kubernetes автоматически экспортируются следующие поля:

| Label        | Pod spec path             |
|--------------|---------------------------|
| `pod`        | `metadata.name`           |
| `namespace`  | `metadata.namespace`      |
| `pod_labels` | `metadata.labels`         |
| `pod_ip`     | `status.podIP`            |
| `image`      | `spec.containers[].image` |
| `container`  | `spec.containers[].name`  |
| `node`       | `spec.nodeName`           |
| `pod_owner`  | `metadata.ownerRef[0]`    |

| Label        | Node spec path                              |
|--------------|---------------------------------------------|
| `node_group` | `metadata.labels[].node.deckhouse.io/group` |

{% alert level="info" %}
Для Splunk поле `pod_labels` не экспортируются, потому что это вложенный объект, который Splunk не поддерживает.
{% endalert %}

#### File

При сборе логов из файловых источников доступен только лейбл `host`,
который содержит hostname сервера, с которого поступил лог.

## Настройка log-shipper из веб-интерфейса Deckhouse

Помимо манифестов, для настройки `log-shipper` можно воспользоваться веб-интерфейсом Deckhouse.

Для настройки модуля `log-shipper` из веб-интерфейса:

1. Установите модуль `console` (#TODO ссылка на доку модуля).
1. Откройте веб-интерфейс и в боковом меню перейдите в раздел **Deckhouse** -> **Модули**.
1. Выберите `log-shipper` в списке модулей. Включите модуль с помощью переключателя.
1. Отредактируйте настройки модуля, используя [примеры конфигурации](#configuration-examples.html)
   или полный список всех доступных параметров (#TODO ссылка на доку со всеми параметрами модуля).
