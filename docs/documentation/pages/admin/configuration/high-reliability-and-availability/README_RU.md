---
title: Высокая надежность и доступность
permalink: ru/admin/high-reliability-and-availability/
description: Высокая надежность и доступность
lang: ru
---

Правильно настроенный кластер должен быть устойчив к различным ситуациям, возникающим в процессе работы: таким как внезапные отключения узлов или компонентов, потеря связности и так далее. Это приводит к ожиданию от кластера стабильности в любой ситуации — намеренно или случайно удалённые компоненты не должны приводить к выходу из строя всей системы, а работоспособность не должна нарушаться.

Кластер под управлением Deckhouse Kubernetes Platform поддерживает режим высокой надежности и доступности (High Availability или HA).

В этом режиме повышается общая отказоустойчивость всей системы и надежность кластера, что обеспечивает стабильную и непрерывную работу, а также восстановление кластера после сбоев с минимальными задержками.

При включенном режиме HA критически важные компоненты кластера запускаются с учетом требуемой избыточности для обеспечения непрерывной работы. В случае отказа любого из экземпляров работа компонентов не прерывается, что позволяет избежать простоев.

Если в кластере **более одного master-узла**, режим HA **включается автоматически**. Это правило верно как при развёртывании кластера сразу с несколькими master-узлами, так и при увеличении количества master-узлов с одного.

Помимо глобального режима HA можно управлять этим режимом [для поддерживающих его компонентов DKP](./enable.html#включение-режима-ha-для-отдельных-компонентов).

## Рекомендации по конфигурации узлов кластера

### Master-узлы

Для обеспечения отказоустойчивости кластера **всегда** используйте не менее трёх master-узлов.

Такое количество обеспечит безотказную работу кластера и позволит безопасно обновлять master-узлы. В большем числе master-узлов нет необходимости, а двух узлов будет недостаточно для обеспечения согласия между master-узлами (кворума) в случае возникновения неполадок с одним из них.

При использовании всего одного master-узла его отказ приведет к сбою всего кластера, так как именно master-узел управляет ключевыми компонентами кластера, обеспечивающими его работу.

### Frontend-узлы

Frontend-узлы балансируют входящий трафик. На них работают Ingress-контроллеры.

Используйте более одного frontend-узла. Frontend-узлы должны выдерживать трафик при отказе как минимум одного frontend-узла.

Например, если в кластере два frontend-узла, то каждый frontend-узел должен справляться со всей нагрузкой на кластер в случае, если второй выйдет из строя. Если в кластере три frontend-узла, то каждый frontend-узел должен выдерживать увеличение нагрузки как минимум в полтора раза.

### Узлы мониторинга

Узлы мониторинга служат для запуска Grafana, Prometheus и других компонентов мониторинга.

В нагруженных кластерах со множеством алертов и большими объемами метрик под мониторинг рекомендуется выделить отдельные узлы. Если этого не сделать, компоненты мониторинга будут размещены на системных узлах.

При выделении узлов под мониторинг важно, чтобы на них были быстрые диски.

### Системные узлы

Системные узлы предназначены для запуска модулей Deckhouse.

Выделите два системных узла. В этом случае модули Deckhouse будут работать на них, не пересекаясь с пользовательскими приложениями кластера.

## Межкластерное взаимодействие

Повышенную отказоустойчивость кластера можно настроить не только внутри одного кластера, но и в рамках межкластерного взаимодействия, построенного на базе режима Service Mesh модуля `istio`.

В этом режиме можно настроить федерацию между двумя или более кластерами, в результате которой в случае проблем с одним из них нагрузка будет перераспределяться на остальные кластера.

Подробнее про настройку этого режима читайте [в разделе настройки Service Mesh](../network/cluster-federation.html)

## Хаос-инжиниринг

Для проверки кластера на устойчивость в DKP предусмотрены инструменты хаос-инжиниринга, которые позволяют прогнозируемо, либо в случайном порядке выводить из строя те или иные компоненты и смотреть, как на это реагирует инфраструктура.

О настройке инструментов хаос-инжиниринга читайте [в разделе «Хаос-инжиниринг»](./chaos-engineering.html).

## Предотвращение перегрузки Kubernetes API (FlowSchema)

В кластере под управлением DKP по умолчанию включён компонент, реализующий [FlowSchema](https://kubernetes.io/docs/concepts/cluster-administration/flow-control/#flowschema) и [PriorityLevelConfiguration](https://kubernetes.io/docs/concepts/cluster-administration/flow-control/#prioritylevelconfiguration) для предотвращения перегрузки Kubernetes API.

`FlowSchema` устанавливает `PriorityLevel` для `list`-запросов от всех сервис-аккаунтов в пространствах имен Deckhouse (у которых установлен label `heritage: deckhouse`) к следующим apiGroup:
* `v1` (Pod, Secret, ConfigMap, Node и т. д.). Это помогает в случае большого количества основных ресурсов в кластере (например, Secret'ов или подов).
* `apps/v1` (DaemonSet, Deployment, StatefulSet, ReplicaSet и т. д.). Это помогает в случае развертывания большого количества приложений в кластере (например, Deployment'ов).
* `deckhouse.io` (custom resource'ы Deckhouse). Это помогает в случае большого количества различных кастомных ресурсов Deckhouse в кластере.
* `cilium.io` (custom resource'ы cilium). Это помогает в случае большого количества политик cilium в кластере.

Все запросы к API, соответствующие `FlowSchema`, помещаются в одну очередь.

Компонент не имеет настроек, но доступны следующие команды:

* Проверка состояние priority level'ов:

  ```shell
  kubectl get --raw /debug/api_priority_and_fairness/dump_priority_levels
  ```

* Проверка состояния очередей priority level'ов:

  ```shell
  kubectl get --raw /debug/api_priority_and_fairness/dump_queues
  ```

Также он передаёт в Grafana следующие метрики:

- `apiserver_flowcontrol_rejected_requests_total` — общее число отброшенных запросов.
- `apiserver_flowcontrol_dispatched_requests_total` — общее число обработанных запросов.
- `apiserver_flowcontrol_current_inqueue_requests` — количество запросов в очередях.
- `apiserver_flowcontrol_current_executing_requests` — количество запросов в обработке.
