{{- range $index, $ng := .Values.nodeManager.internal.nodeGroups }}
  {{- if ($ng).gpu -}}
    {{ $gfdName := printf "gpu-feature-discovery-%s" ( $ng.name | sha256sum | trunc 7 ) }}
    {{ $devicePluginName := printf "nvidia-device-plugin-%s" ( $ng.name | sha256sum | trunc 7 ) }}
    {{- if ($.Values.global.enabledModules | has "vertical-pod-autoscaler") }}
---
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: {{ $gfdName }}
  namespace: d8-nvidia-gpu
  {{- include "helm_lib_module_labels" (list $ (dict "app" "nvidia-gpu" "component" "gpu-feature-discovery")) | nindent 2 }}
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: DaemonSet
    name: {{ $gfdName }}
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: gpu-feature-discovery-ctr
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 100m
        memory: 128Mi
    - containerName: gpu-feature-discovery-sidecar
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 100m
        memory: 128Mi
    {{- end }}
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: {{ $gfdName }}
  namespace: d8-nvidia-gpu
  {{- include "helm_lib_module_labels" (list $ (dict "app" "nvidia-gpu" "component" $gfdName )) | nindent 2 }}
spec:
  selector:
    matchLabels:
      component: {{ $gfdName }}
  template:
    metadata:
      labels:
        component: {{ $gfdName }}
    spec:
      {{- include "helm_lib_module_pod_security_context_run_as_user_root" $ | nindent 6 }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: feature.node.kubernetes.io/pci-10de.present
                    operator: In
                    values:
                      - "true"
              - matchExpressions:
                  - key: feature.node.kubernetes.io/pci-0302_10de.present
                    operator: In
                    values:
                      - "true"
              - matchExpressions:
                  - key: feature.node.kubernetes.io/pci-0300_10de.present
                    operator: In
                    values:
                      - "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      priorityClassName: system-node-critical
      serviceAccountName: nvidia-gpu-feature-discovery
      shareProcessNamespace: true
      initContainers:
      - name: gpu-feature-discovery-init
        image: {{ include "helm_lib_module_image" (list $ "nvidiaDevicePlugin") }}
        command: ["/config-manager"]
        resources:
          requests:
            {{- include "helm_lib_module_ephemeral_storage_only_logs" $ | nindent 12 }}
        {{- if not ( .Values.global.enabledModules | has "vertical-pod-autoscaler") }}
            cpu: 50m
            memory: 64Mi
        {{- end }}
        env:
        - name: ONESHOT
          value: "true"
        - name: KUBECONFIG
          value: ""
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: "spec.nodeName"
        - name: NODE_LABEL
          value: "node.deckhouse.io/device-gpu.config"
        - name: CONFIG_FILE_SRCDIR
          value: "/available-configs"
        - name: CONFIG_FILE_DST
          value: "/config/config.yaml"
        - name: DEFAULT_CONFIG
          value: ""
        - name: SEND_SIGNAL
          value: "false"
        - name: SIGNAL
          value: ""
        - name: PROCESS_TO_SIGNAL
          value: ""
        {{- include "helm_lib_module_container_security_context_privileged_read_only_root_filesystem" $ | nindent 8 }}
        volumeMounts:
          - name: available-configs
            mountPath: /available-configs
          - name: config
            mountPath: /config
      containers:
      - name: gpu-feature-discovery-ctr
        image: {{ include "helm_lib_module_image" (list $ "nvidiaDevicePlugin") }}
        command: ["/gpu-feature-discovery"]
        resources:
          requests:
            {{- include "helm_lib_module_ephemeral_storage_only_logs" $ | nindent 12 }}
        {{- if not ( .Values.global.enabledModules | has "vertical-pod-autoscaler") }}
            cpu: 50m
            memory: 64Mi
        {{- end }}
        env:
          - name: GFD_SLEEP_INTERVAL
            value: 60s
          - name: GFD_FAIL_ON_INIT_ERROR
            value: "true"
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        {{- include "helm_lib_module_container_security_context_privileged" $ | nindent 8 }}
        volumeMounts:
          - name: output-dir
            mountPath: "/etc/kubernetes/node-feature-discovery/features.d"
          - name: host-sys
            mountPath: "/sys"
          - name: available-configs
            mountPath: /available-configs
          - name: config
            mountPath: /config
      - name: gpu-feature-discovery-sidecar
        image: {{ include "helm_lib_module_image" (list $ "nvidiaDevicePlugin") }}
        command: ["/config-manager"]
        resources:
          requests:
            {{- include "helm_lib_module_ephemeral_storage_only_logs" $ | nindent 12 }}
        {{- if not ( .Values.global.enabledModules | has "vertical-pod-autoscaler") }}
            cpu: 50m
            memory: 64Mi
        {{- end }}
        env:
        - name: ONESHOT
          value: "false"
        - name: KUBECONFIG
          value: ""
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: "spec.nodeName"
        - name: NODE_LABEL
          value: "node.deckhouse.io/device-gpu.config"
        - name: CONFIG_FILE_SRCDIR
          value: "/available-configs"
        - name: CONFIG_FILE_DST
          value: "/config/config.yaml"
        - name: DEFAULT_CONFIG
          value: ""
        - name: SEND_SIGNAL
          value: "true"
        - name: SIGNAL
          value: "1" # SIGHUP
        - name: PROCESS_TO_SIGNAL
          value: "gpu-feature-discovery"
        {{- include "helm_lib_module_container_security_context_privileged_read_only_root_filesystem" $ | nindent 8 }}
        volumeMounts:
          - name: available-configs
            mountPath: /available-configs
          - name: config
            mountPath: /config
      volumes:
        - name: output-dir
          hostPath:
            path: "/etc/kubernetes/node-feature-discovery/features.d"
        - name: host-sys
          hostPath:
            path: "/sys"
        - name: available-configs
          configMap:
            name: {{ $devicePluginName }}
        - name: config
          emptyDir: {}
  {{- end }}
{{- end }}
