- name: d8.node-group-update
  rules:
  - alert: D8NodeIsNotUpdating
    expr: |
      max by (node,node_group) (
        node_group_node_status{status="ToBeUpdated"} *
        on(node) group_left() (max by(node) ((kube_node_status_condition{condition="Ready", status="true"} == 1)))
      ) > 0
    for: 5m
    labels:
      tier: cluster
      severity_level: "9"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      summary: Node {{ $labels.node }} is not updating.
      description: |
        Node `{{ $labels.node }}` in NodeGroup `{{ $labels.node_group }}` has a pending update but it's neither receiving it nor attempting to.

        Most likely, Bashible is not handling the update correctly.
        It should annotate the Node with `update.node.deckhouse.io/waiting-for-approval` before the update can proceed.

        Options to investigate the details:

        - Check the expected configuration checksum for the NodeGroup:

          ```shell
          d8 k -n d8-cloud-instance-manager get secret configuration-checksums -o jsonpath={.data.{{ $labels.node_group }}} | base64 -d
          ```

        - Check the current configuration checksum on the Node:

          ```shell
          d8 k get node {{ $labels.node }} -o jsonpath='{.metadata.annotations.node\.deckhouse\.io/configuration-checksum}'
          ```

        - View Bashible logs on the Node:

          ```shell
          journalctl -fu bashible
          ```

  - alert: D8NodeIsNotUpdating
    expr: |
      max by (node,node_group) (
        node_group_node_status{status="Approved"} *
        on(node) group_left() (max by(node) ((kube_node_status_condition{condition="Ready", status="true"} == 1)))
      )> 0
    for: 10m
    labels:
      tier: cluster
      severity_level: "8"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      summary: Node {{ $labels.node }} cannot complete the update.
      description: |
        Node `{{ $labels.node }}` in NodeGroup `{{ $labels.node_group }}` has detected a new update, requested and received approval, but failed to complete the update.

        To investigate the details, view Bashible logs on the Node:

        ```shell
        journalctl -fu bashible
        ```

  - alert: D8NodeIsNotUpdating
    expr: |
      max by (node,node_group) (
        node_group_node_status{status="DisruptionApproved"} *
        on(node) group_left() (max by(node) ((kube_node_status_condition == 1)))
      )> 0
    for: 20m
    labels:
      tier: cluster
      severity_level: "7"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_cause_of__node_unschedulable: "NodeUnschedulable,tier=cluster,prometheus=deckhouse,node={{ $labels.node }}"
      summary: Node {{ $labels.node }} cannot complete the update.
      description: |
        Node `{{ $labels.node }}` in NodeGroup `{{ $labels.node_group }}` detected a new update, requested and received approval, started the update, and encountered a step that could cause downtime.
        The update manager (the `update_approval` hook of the `node-group` module) granted downtime approval, but no success message was received, which indicates that the update has not completed.

        To investigate the details, view Bashible logs on the Node:

        ```shell
        journalctl -fu bashible
        ```

  - alert: D8NodeUpdateStuckWaitingForDisruptionApproval
    expr: |
      max by (node,node_group) (
        node_group_node_status{status="WaitingForDisruptionApproval"} *
        on(node) group_left() (max by(node) (kube_node_status_condition == 1))
      )> 0
    for: 5m
    labels:
      tier: cluster
      severity_level: "8"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      summary: Node {{ $labels.node }} cannot obtain disruption approval.
      description: |
        Node `{{ $labels.node }}` in NodeGroup `{{ $labels.node_group }}` detected a new update, requested and received initial approval, and started the update.
        However, it reached a stage that could cause downtime and was unable to obtain disruption approval.
        A disruption approval is normally issued automatically by the `update_approval` hook of the `node-manager` module.

        To resolve this issue, investigate why the approval could not be granted to proceed with the update.

  - alert: D8NodeGroupIsNotUpdating
    expr: |
      count by (node_group) (
        node_group_node_status{status="WaitingForApproval"} *
        on(node) group_left() (max by(node) ((kube_node_status_condition == 1)))
      ) > 0 and (
        count by (node_group) (
          node_group_node_status{status="Approved"} *
          on(node) group_left() (max by(node) ((kube_node_status_condition == 1)))
        ) == 0
      )
    for: 5m
    labels:
      tier: cluster
      severity_level: "8"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      summary: NodeGroup {{ $labels.node_group }} is not handling the update correctly.
      description: |
        There is a new update available for Nodes in the `{{ $labels.node_group }}` NodeGroup.
        Although Nodes have detected the update, none of them have received approval to start the update process.

        Most likely, there is a problem with the `update_approval` hook of the `node-manager` module.

  - alert: D8ProblematicNodeGroupConfiguration
    expr: |
      max by (status, node_group, node) (node_group_node_status{status="UpdateFailedNoConfigChecksum"}) == 1
    for: 5m
    labels:
      tier: cluster
      severity_level: "8"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__d8_cluster_has_problems_with_nodes_updates: "D8ClusterHasProblemsWithNodesUpdates,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      summary: Node {{ $labels.node }} cannot begin the update.
      description: |
        There is a new update available for Nodes in the `{{ $labels.node_group }}` NodeGroup.
        However, Node `{{ $labels.node }}` cannot begin the update.

        The Node is missing the `node.deckhouse.io/configuration-checksum` annotation, which may indicate that its bootstrap process did not complete correctly.

        Troubleshooting options:

        - Check the `cloud-init` log (`/var/log/cloud-init-output.log`) on the node.
        - Check the NodeGroupConfiguration resource associated with the `{{ $labels.node_group }}` NodeGroup for potential issues.

  - alert: NodeRequiresDisruptionApprovalForUpdate
    expr: |
      max by (node,node_group) (
        node_group_node_status{status="WaitingForManualDisruptionApproval"} *
        on(node) group_left() (max by(node) ((kube_node_status_condition == 1)))
      )> 0
    labels:
      tier: cluster
      severity_level: "8"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__cluster_has_nodes_requiring_disruption_approval_for_update: "ClusterHasNodesRequiringDisruptionApprovalForUpdate,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__cluster_has_nodes_requiring_disruption_approval_for_update: "ClusterHasNodesRequiringDisruptionApprovalForUpdate,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      summary: Node {{ $labels.node }} requires disruption approval to proceed with the update.
      description: |
        Node `{{ $labels.node }}` in NodeGroup `{{ $labels.node_group }}` has detected a new update, received initial approval, and started the update.
        However, it encountered a stage that may cause downtime and requires manual disruption approval, because the NodeGroup is configured with `disruptions.approvalMode: Manual`.

        To resolve the issue, ensure the Node is ready for unsafe updates (drained) and grant disruption approval by annotating the Node with `update.node.deckhouse.io/disruption-approved=`.

        **Caution**:

        - Nodes in manual mode aren't drained automatically.
        - Do not drain master nodes.

        1. To drain the Node and grant the update approval, run the following command:

           ```shell
           d8 k drain {{ $labels.node }} --delete-emptydir-data=true --ignore-daemonsets=true --force=true &&
             d8 k annotate node {{ $labels.node }} update.node.deckhouse.io/disruption-approved=
           ```

        2. Uncordon the Node once the update is complete and the annotation `update.node.deckhouse.io/approved` is removed:

           ```shell
           while d8 k get node {{ $labels.node }} -o json | jq -e '.metadata.annotations | has("update.node.deckhouse.io/approved")' > /dev/null; do sleep 1; done
           d8 k uncordon {{ $labels.node }}
           ```

        If the NodeGroup has multiple Nodes, repeat this process for each one, since only one Node is updated at a time.
        Consider temporarily switching to automatic disruption approval (`disruptions.approvalMode: Automatic`).

  - alert: NodeStuckInDrainingForDisruptionDuringUpdate
    expr: |
      max by (node,node_group) (
        node_group_node_status{status="DrainingForDisruption"} *
        on(node) group_left() (max by(node) ((kube_node_status_condition == 1)))
      )> 0
    for: 2h
    labels:
      tier: cluster
      severity_level: "6"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__cluster_has_nodes_stuck_in_draining_for_disruption_during_update: "ClusterHasNodesStuckInDrainingForDisruptionDuringUpdate,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__cluster_has_nodes_stuck_in_draining_for_disruption_during_update: "ClusterHasNodesStuckInDrainingForDisruptionDuringUpdate,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      summary: Node {{ $labels.node }} is stuck in draining.
      description: |
        Node `{{ $labels.node }}` in NodeGroup `{{ $labels.node_group }}` has detected a new update, requested and received approval, started the update, and reached a step that could cause downtime.
        It is currently stuck in the draining process while waiting for automatic disruption approval.

        To get more details, run the following:

        ```shell
        d8 k -n default get event --field-selector involvedObject.name={{ $labels.node }},reason=ScaleDown --sort-by='.metadata.creationTimestamp'
        ```

  - alert: NodeStuckInDraining
    expr: |
      max by (message, node, node_group) (
        d8_node_draining *
        on (node) group_left (node_group) node_group_node_status{status="Draining"} *
        on (node) group_left () (max by (node) ((kube_node_status_condition == 1)))
      ) > 0
    for: 5m
    labels:
      tier: cluster
      severity_level: "6"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      plk_create_group_if_not_exists__cluster_has_nodes_stuck_in_draining: "ClusterHasNodesStuckInDraining,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_grouped_by__cluster_has_nodes_stuck_in_draining: "ClusterHasNodesStuckInDraining,tier=cluster,prometheus=deckhouse,kubernetes=~kubernetes"
      plk_labels_as_annotations: message
      summary: Node {{ $labels.node }} is stuck in draining.
      description: |
        Node `{{ $labels.node }}` in NodeGroup `{{ $labels.node_group }}` is stuck in the draining process.

        To get more details, run the following:

        ```shell
        d8 k -n default get event --field-selector involvedObject.name={{ $labels.node }},reason=DrainFailed --sort-by='.metadata.creationTimestamp'
        ```

        Error message: {{ $labels.message }}

  - alert: D8BashibleApiserverLocked
    expr: d8_bashible_apiserver_locked == 1
    for: 15m
    labels:
      tier: cluster
      severity_level: "6"
    annotations:
      plk_markup_format: markdown
      plk_protocol_version: "1"
      summary: Bashible-apiserver has been locked for too long.
      description: |
        `Bashible-apiserver` has been locked for an extended period.

        To resolve the issue, check if the `bashible-apiserver` Pods are up-to-date and running:

        ```shell
        d8 k -n d8-cloud-instance-manager get pods -l app=bashible-apiserver
        ```
