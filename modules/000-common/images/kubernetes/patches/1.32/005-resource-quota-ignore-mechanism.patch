diff --git a/pkg/apis/core/validation/validation.go b/pkg/apis/core/validation/validation.go
index 797783912f3..e37e16ec851 100644
--- a/pkg/apis/core/validation/validation.go
+++ b/pkg/apis/core/validation/validation.go
@@ -2236,6 +2236,39 @@ func allowInvalidAPIGroupInDataSourceOrRef(spec *core.PersistentVolumeClaimSpec)
 func ValidatePersistentVolumeClaim(pvc *core.PersistentVolumeClaim, opts PersistentVolumeClaimSpecValidationOptions) field.ErrorList {
 	allErrs := ValidateObjectMeta(&pvc.ObjectMeta, true, ValidatePersistentVolumeName, field.NewPath("metadata"))
 	allErrs = append(allErrs, ValidatePersistentVolumeClaimSpec(&pvc.Spec, field.NewPath("spec"), opts)...)
+	allErrs = append(allErrs, validateResourceQuotaLabels(pvc.Labels, field.NewPath("metadata", "labels"))...)
+	return allErrs
+}
+
+// validateResourceQuotaLabels validates the labels of a pod and pvc
+func validateResourceQuotaLabels(labels map[string]string, fldPath *field.Path) field.ErrorList {
+	allErrs := field.ErrorList{}
+	if labels == nil {
+		return allErrs
+	}
+
+	validLabels := []string{
+		v1.LabelResourceQuotaIgnore,
+		v1.LabelResourceQuotaCapCPU,
+		v1.LabelResourceQuotaCapMemory,
+		v1.LabelResourceQuotaDiscountCPU,
+		v1.LabelResourceQuotaDiscountMemory,
+		v1.LabelResourceQuotaCapStorage,
+		v1.LabelResourceQuotaDiscountStorage,
+	}
+
+	for _, labelKey := range validLabels {
+		if value, exists := labels[labelKey]; exists {
+			labelPath := fldPath.Key(labelKey)
+			quantity, err := resource.ParseQuantity(value)
+			if err != nil {
+				allErrs = append(allErrs, field.Invalid(labelPath, value, fmt.Sprintf("must be a valid quantity: %v", err)))
+			} else {
+				allErrs = append(allErrs, ValidateNonnegativeQuantity(quantity, labelPath)...)
+			}
+		}
+	}
+
 	return allErrs
 }
 
@@ -4070,6 +4103,7 @@ func validatePodMetadataAndSpec(pod *core.Pod, opts PodValidationOptions) field.
 
 	allErrs := ValidateObjectMeta(&pod.ObjectMeta, true, ValidatePodName, metaPath)
 	allErrs = append(allErrs, ValidatePodSpecificAnnotations(pod.ObjectMeta.Annotations, &pod.Spec, metaPath.Child("annotations"), opts)...)
+	allErrs = append(allErrs, validateResourceQuotaLabels(pod.ObjectMeta.Labels, metaPath)...)
 	allErrs = append(allErrs, ValidatePodSpec(&pod.Spec, &pod.ObjectMeta, specPath, opts)...)
 
 	// we do additional validation only pertinent for pods and not pod templates
diff --git a/pkg/quota/v1/evaluator/core/persistent_volume_claims.go b/pkg/quota/v1/evaluator/core/persistent_volume_claims.go
index a4da87b496b..9bf63babd21 100644
--- a/pkg/quota/v1/evaluator/core/persistent_volume_claims.go
+++ b/pkg/quota/v1/evaluator/core/persistent_volume_claims.go
@@ -147,6 +147,35 @@ func (p *pvcEvaluator) Usage(item runtime.Object) (corev1.ResourceList, error) {
 		return result, err
 	}
 
+	// Check for ignore label
+	if pvc.Labels != nil && pvc.Labels[corev1.LabelResourceQuotaIgnore] == "true" {
+		return result, nil
+	}
+
+	// Base storage usage
+	storageUsage := p.getStorageUsage(pvc)
+	if storageUsage == nil {
+		return result, nil
+	}
+
+	// Apply storage discount if specified
+	if pvc.Labels != nil {
+		if discountStr, exists := pvc.Labels[corev1.LabelResourceQuotaDiscountStorage]; exists {
+			if discount, err := resource.ParseQuantity(discountStr); err == nil {
+				storageUsage.Sub(discount)
+				if storageUsage.Sign() == -1 {
+					storageUsage = resource.NewQuantity(0, resource.DecimalSI)
+				}
+			}
+		}
+		// Apply storage cap if specified
+		if capStr, exists := pvc.Labels[corev1.LabelResourceQuotaCapStorage]; exists {
+			if capQty, err := resource.ParseQuantity(capStr); err == nil && storageUsage.Cmp(capQty) > 0 {
+				storageUsage = &capQty
+			}
+		}
+	}
+
 	// charge for claim
 	result[corev1.ResourcePersistentVolumeClaims] = *(resource.NewQuantity(1, resource.DecimalSI))
 	result[pvcObjectCountName] = *(resource.NewQuantity(1, resource.DecimalSI))
@@ -156,14 +185,11 @@ func (p *pvcEvaluator) Usage(item runtime.Object) (corev1.ResourceList, error) {
 		result[storageClassClaim] = *(resource.NewQuantity(1, resource.DecimalSI))
 	}
 
-	requestedStorage := p.getStorageUsage(pvc)
-	if requestedStorage != nil {
-		result[corev1.ResourceRequestsStorage] = *requestedStorage
-		// charge usage to the storage class (if present)
-		if len(storageClassRef) > 0 {
-			storageClassStorage := corev1.ResourceName(storageClassRef + storageClassSuffix + string(corev1.ResourceRequestsStorage))
-			result[storageClassStorage] = *requestedStorage
-		}
+	result[corev1.ResourceRequestsStorage] = *storageUsage
+	// charge usage to the storage class (if present)
+	if len(storageClassRef) > 0 {
+		storageClassStorage := corev1.ResourceName(storageClassRef + storageClassSuffix + string(corev1.ResourceRequestsStorage))
+		result[storageClassStorage] = *storageUsage
 	}
 
 	return result, nil
diff --git a/pkg/quota/v1/evaluator/core/pods.go b/pkg/quota/v1/evaluator/core/pods.go
index 8efdec6cc2b..848e5e2b35c 100644
--- a/pkg/quota/v1/evaluator/core/pods.go
+++ b/pkg/quota/v1/evaluator/core/pods.go
@@ -363,6 +363,11 @@ func PodUsageFunc(obj runtime.Object, clock clock.Clock) (corev1.ResourceList, e
 		return corev1.ResourceList{}, err
 	}
 
+	// Check for ignore label
+	if pod.Labels != nil && pod.Labels[corev1.LabelResourceQuotaIgnore] == "true" {
+		return corev1.ResourceList{}, nil
+	}
+
 	// always quota the object count (even if the pod is end of life)
 	// object count quotas track all objects that are in storage.
 	// where "pods" tracks all pods that have not reached a terminal state,
@@ -385,10 +390,81 @@ func PodUsageFunc(obj runtime.Object, clock clock.Clock) (corev1.ResourceList, e
 	requests := resourcehelper.PodRequests(pod, opts)
 	limits := resourcehelper.PodLimits(pod, opts)
 
-	result = quota.Add(result, podComputeUsageHelper(requests, limits))
+	podUsage := podComputeUsageHelper(requests, limits)
+
+	// Apply discount and cap if specified via labels
+	// Discounts/caps apply to requests.* and limits.* resources
+	if pod.Labels != nil {
+		// CPU discount
+		if discountStr, exists := pod.Labels[corev1.LabelResourceQuotaDiscountCPU]; exists {
+			if discount, err := resource.ParseQuantity(discountStr); err == nil {
+				applyDiscount(podUsage, corev1.ResourceRequestsCPU, discount)
+				applyDiscount(podUsage, corev1.ResourceLimitsCPU, discount)
+			}
+		}
+		// CPU cap
+		if capStr, exists := pod.Labels[corev1.LabelResourceQuotaCapCPU]; exists {
+			if capQty, err := resource.ParseQuantity(capStr); err == nil {
+				applyCap(podUsage, corev1.ResourceRequestsCPU, capQty)
+				applyCap(podUsage, corev1.ResourceLimitsCPU, capQty)
+			}
+		}
+
+		// Memory discount
+		if discountStr, exists := pod.Labels[corev1.LabelResourceQuotaDiscountMemory]; exists {
+			if discount, err := resource.ParseQuantity(discountStr); err == nil {
+				applyDiscount(podUsage, corev1.ResourceRequestsMemory, discount)
+				applyDiscount(podUsage, corev1.ResourceLimitsMemory, discount)
+			}
+		}
+		// Memory cap
+		if capStr, exists := pod.Labels[corev1.LabelResourceQuotaCapMemory]; exists {
+			if capQty, err := resource.ParseQuantity(capStr); err == nil {
+				applyCap(podUsage, corev1.ResourceRequestsMemory, capQty)
+				applyCap(podUsage, corev1.ResourceLimitsMemory, capQty)
+			}
+		}
+
+		// Ephemeral-storage discount
+		if discountStr, exists := pod.Labels[corev1.LabelResourceQuotaDiscountStorage]; exists {
+			if discount, err := resource.ParseQuantity(discountStr); err == nil {
+				applyDiscount(podUsage, corev1.ResourceRequestsEphemeralStorage, discount)
+				applyDiscount(podUsage, corev1.ResourceLimitsEphemeralStorage, discount)
+			}
+		}
+		// Ephemeral-storage cap
+		if capStr, exists := pod.Labels[corev1.LabelResourceQuotaCapStorage]; exists {
+			if capQty, err := resource.ParseQuantity(capStr); err == nil {
+				applyCap(podUsage, corev1.ResourceRequestsEphemeralStorage, capQty)
+				applyCap(podUsage, corev1.ResourceLimitsEphemeralStorage, capQty)
+			}
+		}
+	}
+
+	result = quota.Add(result, podUsage)
 	return result, nil
 }
 
+// applyDiscount subtracts discount from the resource in usage, ensuring the result is non-negative
+func applyDiscount(usage corev1.ResourceList, resourceName corev1.ResourceName, discount resource.Quantity) {
+	if val, exists := usage[resourceName]; exists {
+		val.Sub(discount)
+		if val.Sign() == -1 {
+			val = *resource.NewQuantity(0, resource.DecimalSI)
+		}
+		usage[resourceName] = val
+	}
+}
+
+// applyCap limits the resource in usage to the cap value
+func applyCap(usage corev1.ResourceList, resourceName corev1.ResourceName, cap resource.Quantity) {
+	if val, exists := usage[resourceName]; exists {
+		if val.Cmp(cap) > 0 {
+			usage[resourceName] = cap
+		}
+	}
+}
+
 func isBestEffort(pod *corev1.Pod) bool {
 	return qos.GetPodQOS(pod) == corev1.PodQOSBestEffort
 }
diff --git a/staging/src/k8s.io/api/core/v1/well_known_labels.go b/staging/src/k8s.io/api/core/v1/well_known_labels.go
index 8c3cb87b82a..499e454a207 100644
--- a/staging/src/k8s.io/api/core/v1/well_known_labels.go
+++ b/staging/src/k8s.io/api/core/v1/well_known_labels.go
@@ -71,4 +71,13 @@ const (
 	LabelNodeExcludeBalancers = "node.kubernetes.io/exclude-from-external-load-balancers"
 	// LabelMetadataName is the label name which, in-tree, is used to automatically label namespaces, so they can be selected easily by tools which require definitive labels
 	LabelMetadataName = "kubernetes.io/metadata.name"
+
+	// Resource quota control labels
+	LabelResourceQuotaIgnore          = "resources.k8s.io/ignore"
+	LabelResourceQuotaDiscountStorage = "resources.k8s.io/discount-storage"
+	LabelResourceQuotaCapStorage      = "resources.k8s.io/cap-storage"
+	LabelResourceQuotaDiscountCPU     = "resources.k8s.io/discount-cpu"
+	LabelResourceQuotaCapCPU          = "resources.k8s.io/cap-cpu"
+	LabelResourceQuotaDiscountMemory  = "resources.k8s.io/discount-memory"
+	LabelResourceQuotaCapMemory       = "resources.k8s.io/cap-memory"
 )
