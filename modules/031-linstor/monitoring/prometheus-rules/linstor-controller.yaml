- name: kubernetes.linstor.controller_state
  rules:
    - alert: D8LinstorControllerGrowingErrorReports
      expr: sum by (module) (increase(linstor_error_reports_count{module="CONTROLLER"}[5m])) >= 20
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=cluster,d8_module=linstor,d8_component=linstor-controller"
        plk_grouped_by__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=~tier,prometheus=deckhouse"
        summary: LINSTOR controller has errors
        description: |
          LINSTOR controller has continuously growing amount of error reports

          The recommended course of action:
          1. Check the Pod logs: `kubectl -n d8-linstor logs -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-controller -c linstor-controller`
          2. Check the LINSTOR error reports: `kubectl exec -n d8-linstor deploy/linstor-controller -- linstor err list | grep 'C|linstor-controller'`

    - alert: D8LinstorControllerTargetDown
      expr: max by (job) (up{job="linstor-controller"} == 0)
      for: 1m
      labels:
        severity_level: "6"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=cluster,d8_module=linstor,d8_component=linstor-controller"
        plk_grouped_by__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=~tier,prometheus=deckhouse"
        plk_ignore_labels: "job"
        summary: Prometheus cannot scrape the linstor-controller metrics.
        description: |
          The recommended course of action:
          1. Check the Pod status: `kubectl -n d8-linstor get pod -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-controller`
          2. Or check the Pod logs: `kubectl -n d8-linstor logs -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-controller -c linstor-controller`

    - alert: D8LinstorControllerTargetAbsent
      expr: absent(up{job="linstor-controller"}) == 1
      labels:
        severity_level: "6"
        tier: cluster
      for: 15m
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_ignore_labels: "job"
        plk_create_group_if_not_exists__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=cluster,d8_module=linstor,d8_component=linstor-controller"
        plk_grouped_by__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=~tier,prometheus=deckhouse"
        summary: There is no `linstor-controller` target in Prometheus.
        description: |
          The recommended course of action:
          1. Check the Pod status: `kubectl -n d8-linstor get pod -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-controller`
          2. Or check the Pod logs: `kubectl -n d8-linstor logs -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-controller -c linstor-controller`

    - alert: D8LinstorControllerPodIsNotReady
      expr: min by (pod) (kube_pod_status_ready{condition="true", namespace="d8-linstor", pod=~"linstor-controller-.*"}) != 1
      labels:
        severity_level: "6"
        tier: cluster
      for: 30m
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_labels_as_annotations: "pod"
        plk_create_group_if_not_exists__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=cluster,d8_module=linstor,d8_component=linstor-controller"
        plk_grouped_by__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=~tier,prometheus=deckhouse"
        summary: The linstor-controller Pod is NOT Ready.
        description: |
          The recommended course of action:
          1. Retrieve details of the Deployment: `kubectl -n d8-linstor describe deploy linstor-controller`
          2. View the status of the Pod and try to figure out why it is not running: `kubectl -n d8-linstor describe pod -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-controller`

    - alert: D8LinstorControllerPodIsNotRunning
      expr: absent(kube_pod_status_phase{namespace="d8-linstor",phase="Running",pod=~"linstor-controller-.*"})
      labels:
        severity_level: "6"
        tier: cluster
      for: 30m
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=cluster,d8_module=linstor,d8_component=linstor-controller"
        plk_grouped_by__d8_linstor_controller_health: "D8LinstorControllerHealth,tier=~tier,prometheus=deckhouse"
        summary: The linstor-controller Pod is NOT Running.
        description: |
          The recommended course of action:
          1. Retrieve details of the Deployment: `kubectl -n d8-linstor describe deploy linstor-controller`
          2. View the status of the Pod and try to figure out why it is not running: `kubectl -n d8-linstor describe pod -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-controller`
