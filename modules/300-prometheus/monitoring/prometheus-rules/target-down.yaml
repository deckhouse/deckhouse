- name: d8.prometheus.target_down
  rules:
  - alert: TargetDown
    expr: up == 0 unless on (job) ALERTS{alertname=~".+TargetDown"}
    for: 10m
    labels:
      severity_level: "7"
    annotations:
      plk_protocol_version: "1"
      plk_labels_as_annotations: "instance,pod"
      description: '{{ $labels.job }} target is down.'
      summary: Target is down

  - alert: TargetDown
    expr: up == 0 unless on (job) ALERTS{alertname=~".+TargetDown"}
    for: 30m
    labels:
      severity_level: "6"
    annotations:
      plk_protocol_version: "1"
      plk_labels_as_annotations: "instance,pod"
      description: '{{ $labels.job }} target is down.'
      summary: Target is down

  - alert: TargetDown
    expr: up == 0 unless on (job) ALERTS{alertname=~".+TargetDown"}
    for: 60m
    labels:
      severity_level: "5"
    annotations:
      plk_protocol_version: "1"
      plk_labels_as_annotations: "instance,pod"
      description: '{{ $labels.job }} target is down.'
      summary: Target is down

  - alert: TargetSampleLimitExceeded
    expr: |
      sum without (
        exported_instance, instance, exported_job, exported_pod, pod, scrape_source, tier, hook, module
      ) (
        label_replace(
          d8_prometheus_target_limits_metrics,
        "job", "$1", "exported_job", "(.*)")
      ) > 0
    for: __SCRAPE_INTERVAL_X_2__
    labels:
      severity_level: "7"
    annotations:
      plk_protocol_version: "1"
      plk_markup_format: "markdown"
      description: |
        Some targets are down because of a sample limit exceeded.
      summary: Scrapes are exceding sample limit
