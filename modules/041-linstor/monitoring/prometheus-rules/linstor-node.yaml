- name: kubernetes.linstor.node_state
  rules:
    - alert: D8LinstorNodeIsNotOnline
      expr: max by (exported_node) (linstor_node_state{nodetype="SATELLITE"} != 2)
      for: 5m
      labels:
        severity_level: "6"
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: LINSTOR node is not ONLINE
        description: |
          LINSTOR node {{ $labels.exported_node }} is not ONLINE

          The recommended course of action:
          1. Check the LINSTOR node status: `kubectl exec -n d8-linstor deploy/linstor-controller -- linstor node list -n {{ $labels.exported_node }}`
          2. Check the Pod status: `kubectl -n d8-linstor get pod --field-selector=spec.nodeName={{ $labels.exported_node }} -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-node -o name`

    - alert: D8LinstorSatelliteGrowingErrorReports
      expr: sum by (hostname) (increase(linstor_error_reports_count{module="SATELLITE"}[5m])) >= 20
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: LINSTOR satellite has errors
        description: |
          LINSTOR satellite {{ $labels.hostname }} has continuously growing amount of error reports

          The recommended course of action:
          1. Check the Pod logs: `kubectl -n d8-linstor logs $(kubectl -n d8-linstor get pod --field-selector=spec.nodeName={{ $labels.node }} -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-node -o name) -c linstor-satellite`
          2. Check the LINSTOR error reports: `kubectl exec -n d8-linstor deploy/linstor-controller -- linstor err list -n {{ $labels.hostname }}`

    - alert: D8LinstorNodePodIsNotReady
      expr: min by (pod) (avg by(node,pod,namespace)(kube_pod_info{}) * on(pod, namespace) group_right(node) kube_pod_status_ready{condition="true", namespace="d8-linstor", pod=~"linstor-node-.*"}) != 1
      for: 10m
      labels:
        severity_level: "6"
        tier: cluster
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_labels_as_annotations: "pod"
        plk_create_group_if_not_exists__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: The linstor-node Pod is NOT Ready.
        description: |
          The recommended course of action:
          1. Retrieve details of the Deployment: `kubectl -n d8-linstor describe daemonset linstor-node`
          2. View the status of the Pod and try to figure out why it is not running: `kubectl -n d8-linstor describe pod --field-selector=spec.nodeName={{ $labels.node }} -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-node`

    - alert: D8LinstorNodePodIsNotRunning
      expr: absent(avg by(node,pod,namespace)(kube_pod_info{}) * on(pod, namespace) group_right(node) kube_pod_status_phase{namespace="d8-linstor",phase="Running",pod=~"linstor-node-.*"})
      for: 2m
      labels:
        severity_level: "6"
        tier: cluster
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_linstor_node_health: "D8LinstorNodeHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: The linstor-node Pod is NOT Running.
        description: |
          The recommended course of action:
          1. Retrieve details of the DaemonSet: `kubectl -n d8-linstor describe daemonset linstor-node`
          2. View the status of the Pod and try to figure out why it is not running: `kubectl -n d8-linstor describe pod --field-selector=spec.nodeName={{ $labels.node }} -l app.kubernetes.io/instance=linstor,app.kubernetes.io/managed-by=piraeus-operator,app.kubernetes.io/name=piraeus-node`
