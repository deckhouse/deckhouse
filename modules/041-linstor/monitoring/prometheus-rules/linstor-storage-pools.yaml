- name: kubernetes.linstor.storage_pool_state
  rules:
    - alert: D8LinstorStoragePoolHasErrors
      expr: max by (exported_node, storage_pool) (linstor_storage_pool_error_count != 0)
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_linstor_storage_pool_health: "D8LinstorStoragePoolHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_linstor_storage_pool_health: "D8LinstorStoragePoolHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: LINSTOR storage pool has errors
        description: |
          LINSTOR storage pool {{ $labels.storage_pool }} on node {{ $labels.exported_node }} has errors

          The recommended course of action:
          1. Check the LINSTOR storage pool: `kubectl exec -n d8-linstor deploy/linstor-controller -- linstor storage-pool list -n {{ $labels.exported_node }} -s {{ $labels.storage_pool }}`
          2. Check backing storage devices

    - alert: D8LinstorStoragePoolCapacityPressure
      expr: max by (exported_node, storage_pool) (linstor_storage_pool_capacity_free_bytes * 100 / linstor_storage_pool_capacity_total_bytes < 10)
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
      annotations:
        plk_markup_format: "markdown"
        plk_protocol_version: "1"
        plk_create_group_if_not_exists__d8_linstor_storage_pool_health: "D8LinstorStoragePoolHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        plk_grouped_by__d8_linstor_storage_pool_health: "D8LinstorStoragePoolHealth,tier=~tier,prometheus=deckhouse,kubernetes=~kubernetes"
        summary: Storage pool running out of free space
        description: |
          LINSTOR storage pool {{ $labels.storage_pool }} on node {{ $labels.exported_node }} has less than 10% space left. Current free space: {{ $value }}%

          The recommended course of action:
          1. Check the LINSTOR storage pool: `kubectl exec -n d8-linstor deploy/linstor-controller -- linstor storage-pool list -n {{ $labels.exported_node }} -s {{ $labels.storage_pool }}`
          2. Check the LINSTOR volumes: `kubectl exec -n d8-linstor deploy/linstor-controller -- linstor volume list -n {{ $labels.exported_node }} -s {{ $labels.storage_pool }}`
          3. Consider adding more backing devices or relocating some resources to other nodes:
             ```
             alias linstor="kubectl exec -n d8-linstor deploy/linstor-controller -- linstor"
             linstor resource-definition auto-place <res> --place-count +1 -s {{ $labels.storage_pool }}
             linstor resource-definition wait-sync <res>
             linstor resource delete {{ $labels.exported_node }} <res>
             ```
