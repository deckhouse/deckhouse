- name: d8.upmeter.availability
  rules:
    - alert: D8UpmeterServerPodIsNotReady
      expr: |
        min by (pod) (
          kube_controller_pod{namespace="d8-upmeter", controller_type="StatefulSet", controller_name="upmeter"}
          * on (pod) group_right() kube_pod_status_ready{condition="true", namespace="d8-upmeter"}
        ) != 1
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
        d8_module: upmeter
        d8_component: server
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_upmeter_unavailable: "D8UpmeterUnavailable,prometheus=deckhouse,tier=cluster,d8_module=upmeter,d8_component=server"
        plk_grouped_by__d8_upmeter_unavailable: "D8UpmeterUnavailable,tier=cluster,prometheus=deckhouse"
        plk_labels_as_annotations: "pod"
        summary: Upmeter server is not Ready

    - alert: D8UpmeterAgentPodIsNotReady
      expr: |
        min by (pod) (
          kube_controller_pod{namespace="d8-upmeter", controller_type="DaemonSet", controller_name="upmeter-agent"}
          * on (pod) group_right() kube_pod_status_ready{condition="true", namespace="d8-upmeter"}
        ) != 1
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
        d8_module: upmeter
        d8_component: agent
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_upmeter_unavailable: "D8UpmeterUnavailable,prometheus=deckhouse,tier=cluster,d8_module=upmeter,d8_component=agent"
        plk_grouped_by__d8_upmeter_unavailable: "D8UpmeterUnavailable,tier=cluster,prometheus=deckhouse"
        plk_labels_as_annotations: "pod"
        summary: Upmeter agent is not Ready

    - alert: D8UpmeterServerReplicasUnavailable
      expr: |
        absent(
          max by (namespace) (
            kube_controller_replicas{controller_name="upmeter",controller_type="StatefulSet"}
          )
          <=
          count by (namespace) (
            kube_controller_pod{controller_name="upmeter",controller_type="StatefulSet"}
            * on(pod) group_right() kube_pod_status_phase{namespace="d8-upmeter", phase="Running"} == 1
          )
        ) == 1
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
        d8_module: upmeter
        d8_component: server
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_upmeter_unavailable: "D8UpmeterUnavailable,prometheus=deckhouse,tier=cluster,d8_module=upmeter,d8_component=server"
        plk_grouped_by__d8_upmeter_unavailable: "D8UpmeterUnavailable,tier=cluster,prometheus=deckhouse"
        plk_labels_as_annotations: "phase"
        summary: One or more Upmeter server pods is NOT Running
        description: |-
          Check StatefulSet status:
          `kubectl -n d8-upmeter get statefulset upmeter -o json | jq .status`

          Check the status of its pod:
          `kubectl -n d8-upmeter get pods upmeter-0 -o json | jq '.items[] | {(.metadata.name):.status}'`

    - alert: D8UpmeterAgentReplicasUnavailable
      expr: |
        absent(
          max by (namespace) (
            kube_controller_replicas{controller_name="upmeter-agent",controller_type="DaemonSet"}
          )
          <=
          count by (namespace) (
            kube_controller_pod{controller_name="upmeter-agent",controller_type="DaemonSet"}
            * on(pod) group_right() kube_pod_status_phase{namespace="d8-upmeter", phase="Running"} == 1
          )
        ) == 1
      for: 5m
      labels:
        severity_level: "6"
        tier: cluster
        d8_module: upmeter
        d8_component: agent
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_upmeter_unavailable: "D8UpmeterUnavailable,prometheus=deckhouse,tier=cluster,d8_module=upmeter,d8_component=agent"
        plk_grouped_by__d8_upmeter_unavailable: "D8UpmeterUnavailable,tier=cluster,prometheus=deckhouse"
        plk_labels_as_annotations: "phase"
        summary: One or more Upmeter agent pods is NOT Running
        description: |-
          Check DaemonSet status:
          `kubectl -n d8-upmeter get daemonset upmeter-agent -o json | jq .status`

          Check the status of its pod:
          `kubectl -n d8-upmeter get pods -l app=upmeter-agent -o json | jq '.items[] | {(.metadata.name):.status}'`

- name: d8.upmeter.malfunctioning
  rules:
    - alert: D8UpmeterServerPodIsRestartingTooOften
      expr: |
        max by (pod) (
          kube_controller_pod{namespace="d8-upmeter", controller_type="StatefulSet", controller_name="upmeter"}
          * on (pod) group_right() increase(kube_pod_container_status_restarts_total{namespace="d8-upmeter"}[1h])
          and
          kube_controller_pod{namespace="d8-upmeter", controller_type="StatefulSet", controller_name="upmeter"}
          * on (pod) group_right() kube_pod_container_status_restarts_total{namespace="d8-upmeter"}
        ) > 5
      for: 5m
      labels:
        severity_level: "9"
        tier: cluster
        d8_module: upmeter
        d8_component: server
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_upmeter_malfunctioning: "D8UpmeterMalfunctioning,prometheus=deckhouse,tier=cluster,d8_module=upmeter,d8_component=server"
        plk_grouped_by__d8_upmeter_malfunctioning: "D8UpmeterMalfunctioning,tier=cluster,prometheus=deckhouse"
        plk_labels_as_annotations: "pod"
        summary: Upmeter server is restarting too often.
        description: |
          Restarts for the last hour: {{ $value }}.

          Upmeter server should not restart too often. It should always be running and collecting episodes.
          Check its logs to find the problem:
          `kubectl -n d8-upmeter logs -f upmeter-0 upmeter`

- name: d8.upmeter.smoke-mini
  rules:
    - alert: D8SmokeMiniNotBoundPersistentVolumeClaims
      for: 1h
      expr: |
        max by (persistentvolumeclaim, phase) (
          kube_persistentvolumeclaim_status_phase{
            namespace="d8-upmeter",
            persistentvolumeclaim=~"disk-smoke-mini-[a-z]-0",
            phase!="Bound"
          } == 1
        )
      labels:
        severity_level: "9"
        tier: cluster
        d8_module: upmeter
        d8_component: smoke-mini
      annotations:
        plk_protocol_version: "1"
        plk_markup_format: "markdown"
        plk_create_group_if_not_exists__d8_smoke_mini_unavailable: "D8SmokeMiniUnavailable,prometheus=deckhouse,tier=cluster,d8_module=upmeter,d8_component=smoke-mini"
        plk_grouped_by__d8_smoke_mini_unavailable: "D8SmokeMiniUnavailable,tier=cluster,prometheus=deckhouse"
        summary: Smoke-mini has unbound or lost persistent volume claims.
        description: |
          {{ $labels.persistentvolumeclaim }} persistent volume claim status is {{ $labels.phase }}.

          There is a problem with pv provisioning. Check the status of the pvc o find the problem:
          `kubectl -n d8-upmeter get pvc {{ $labels.persistentvolumeclaim }}`

          If you have no disk provisioning system in the cluster,
          you can disable ordering volumes for the some-mini through the module settings.
